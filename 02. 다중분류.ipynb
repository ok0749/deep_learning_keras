{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "willing-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-firmware",
   "metadata": {},
   "source": [
    "### iris 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "descending-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threaded-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정보\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pleasant-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>specis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "        specis  \n",
       "0       setosa  \n",
       "1       setosa  \n",
       "2       setosa  \n",
       "3       setosa  \n",
       "4       setosa  \n",
       "..         ...  \n",
       "145  virginica  \n",
       "146  virginica  \n",
       "147  virginica  \n",
       "148  virginica  \n",
       "149  virginica  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 프레임 생성\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['specis'] = iris.target\n",
    "iris_df['specis'] = iris_df['specis'].apply(lambda x: iris.target_names[x])\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "formal-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입출력 데이터 구성\n",
    "x_data = iris_df.drop('specis', axis=1)\n",
    "y_data = iris_df['specis']\n",
    "\n",
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-kansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 데이터 라벨 인코딩\n",
    "e = LabelEncoder()\n",
    "y = e.fit_transform(y_data)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "impressive-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 데이터 원-핫인코딩\n",
    "y_encoded = to_categorical(y)\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facial-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed값 설정\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "computational-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "# feature 4개\n",
    "model.add(Dense(16, input_dim=4, activation='relu'))\n",
    "# target 3종류\n",
    "# 다중분류 -> softmax\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "small-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infinite-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 2.4696 - accuracy: 0.3587\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.7039\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.7668\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.8565\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7828\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.9243\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.9238\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8599\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8614\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.9815\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.9705\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.9606\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9796\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.9577\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.9643\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9611\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9630\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9481\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.9152\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9540\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9944\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9803\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9784\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9681\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9658\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9950\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9759\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9677\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9643\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9764\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9880\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9472\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9797\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9724\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9900\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9572\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9914\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9732\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9865\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9757\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9869\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9270\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9683\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9823\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9557\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9519\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9742\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9643\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144dec650>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행\n",
    "model.fit(x_data, y_encoded, epochs=50, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "increasing-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08690375834703445, 0.9800000190734863]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "model.evaluate(x_data, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "weighted-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = np.argmax(model.predict(x_data), axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continental-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      0.96      0.97        50\n",
      "           2       0.96      0.98      0.97        50\n",
      "\n",
      "    accuracy                           0.98       150\n",
      "   macro avg       0.98      0.98      0.98       150\n",
      "weighted avg       0.98      0.98      0.98       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
